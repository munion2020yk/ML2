import streamlit as st
import FinanceDataReader as fdr
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from datetime import datetime, timedelta
import torch
import torch.nn as nn
import joblib
import warnings

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.filterwarnings('ignore')

# --- 1. (í•„ìˆ˜) LSTM ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ ---
# train_model.pyì— ìˆëŠ” ëª¨ë¸ í´ë˜ìŠ¤ì™€ "ì •í™•íˆ ë™ì¼í•œ êµ¬ì¡°"ì—¬ì•¼ í•©ë‹ˆë‹¤.
class LSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size):
        super(LSTMModel, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size) 
        
    def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        out, _ = self.lstm(x, (h0, c0))  
        out = self.fc(out[:, -1, :])
        return out

# --- 2. ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ---
# @st.cache_resource: ëª¨ë¸, ìŠ¤ì¼€ì¼ëŸ¬ ë“± ë¦¬ì†ŒìŠ¤ë¥¼ ìºì‹œ (ì•± ì‹¤í–‰ ì‹œ 1íšŒë§Œ ë¡œë“œ)
@st.cache_resource
def load_model_and_scaler():
    """
    ì €ì¥ëœ LSTM ëª¨ë¸('lstm_model.pth')ê³¼ ìŠ¤ì¼€ì¼ëŸ¬('scaler.joblib')ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    """
    # ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° (train_model.pyì™€ ë™ì¼í•´ì•¼ í•¨)
    INPUT_SIZE = 3
    HIDDEN_SIZE = 64
    NUM_LAYERS = 2
    OUTPUT_SIZE = 2
    
    # ëª¨ë¸ ì•„í‚¤í…ì²˜ ë¡œë“œ
    model = LSTMModel(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, OUTPUT_SIZE)
    
    # ì €ì¥ëœ íŒŒë¼ë¯¸í„°(Weight) ë¡œë“œ
    try:
        # 'cuda' ì¥ì¹˜ê°€ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ map_location='cpu' ì¶”ê°€ (ì¤‘ìš”)
        model.load_state_dict(torch.load('lstm_model.pth', map_location=torch.device('cpu')))
    except FileNotFoundError:
        st.error("ì˜¤ë¥˜: 'lstm_model.pth' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.error("GitHub ë¦¬í¬ì§€í† ë¦¬ì— 'lstm_model.pth' íŒŒì¼ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return None, None
        
    model.eval() # ì˜ˆì¸¡ ëª¨ë“œë¡œ ì„¤ì • (ì¤‘ìš”)
    
    # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
    try:
        scaler = joblib.load('scaler.joblib')
    except FileNotFoundError:
        st.error("ì˜¤ë¥˜: 'scaler.joblib' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.error("GitHub ë¦¬í¬ì§€í† ë¦¬ì— 'scaler.joblib' íŒŒì¼ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return None, None
        
    return model, scaler

# --- 3. ë°ì´í„° ë¡œë“œ ë° ì˜ˆì¸¡ ìˆ˜í–‰ ---
# @st.cache_data: ë°˜í™˜ê°’ì´ ë°ì´í„°(DataFrame ë“±)ì¼ ë•Œ ì‚¬ìš©
@st.cache_data(ttl=600)
def load_data_and_predict(_model, _scaler):
    """
    ì˜ˆì¸¡ì— í•„ìš”í•œ 'ìµœê·¼' ë°ì´í„°ë§Œ ë¡œë“œí•˜ê³ , ëª¨ë¸ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    (ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ëŠ” _model, _scalerë¡œ ë°›ì•„ì„œ ì‚¬ìš©)
    """
    # --- 3-1. KRX ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë¡œë“œ (ì œê±°ë¨) ---
    # í•˜ë“œì½”ë”©ëœ ë¦¬ìŠ¤íŠ¸ ì‚¬ìš© (train_model.pyì™€ ë™ì¼)
    target_symbols = {'005930': 'ì‚¼ì„±ì „ì', '000660': 'SKí•˜ì´ë‹‰ìŠ¤'}
    sector_symbols = ['005930', '000660', '042700', '036930', '055550']
    sector_names = ['ì‚¼ì„±ì „ì', 'SKí•˜ì´ë‹‰ìŠ¤', 'í•œë¯¸ë°˜ë„ì²´', 'ì£¼ì„±ì—”ì§€ë‹ˆì–´ë§', 'ë¦¬ë…¸ê³µì—…']
    
    # --- 3-2. ì˜ˆì¸¡ì— í•„ìš”í•œ ìµœê·¼ ë°ì´í„° ìˆ˜ì§‘ ---
    # look_back=10 ì´ì—ˆìœ¼ë¯€ë¡œ, ìµœê·¼ 30ì¼ì¹˜ ì •ë„ ë„‰ë„‰í•˜ê²Œ ë°›ìŒ
    start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
    all_symbols_to_download = sector_symbols # ìˆ˜ì •ë¨
    
    df_dict = {}
    for symbol in all_symbols_to_download: # ìˆ˜ì •ë¨
        try:
            df_data = fdr.DataReader(symbol, start_date) # ìˆ˜ì •ë¨
            if df_data.empty or 'Close' not in df_data.columns:
                st.error(f"{symbol} ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨. ì˜ˆì¸¡ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                return None, None, None, None
            df_dict[symbol] = df_data['Close'] # ìˆ˜ì •ë¨
        except Exception as e:
            st.error(f"{symbol} ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None, None, None, None
        
    df_prices = pd.DataFrame(df_dict).fillna(method='ffill').dropna()
    
    # ë°ì´í„°ê°€ 10ì¼ì¹˜ ë¯¸ë§Œì¼ ê²½ìš° ì—ëŸ¬ ì²˜ë¦¬
    if len(df_prices) < 10:
        st.error("ì˜¤ë¥˜: ì˜ˆì¸¡ì— í•„ìš”í•œ ìµœê·¼ 10ì¼ì¹˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return None, None, None, None

    # --- 3-3. Feature Engineering (train_model.pyì™€ ë™ì¼) ---
    actual_used_symbols = list(df_dict.keys()) # ìˆ˜ì •ë¨
    df_prices['Sector_Avg'] = df_prices[actual_used_symbols].mean(axis=1) # ìˆ˜ì •ë¨
    features = ['005930', '000660', 'Sector_Avg']
    
    # ì˜ˆì¸¡ì— ì‚¬ìš©í•  ë§ˆì§€ë§‰ 10ì¼(look_back) ë°ì´í„° ì¶”ì¶œ
    last_10_days_data = df_prices[features].tail(10).values
    
    # --- 3-4. ìŠ¤ì¼€ì¼ë§ ë° ì˜ˆì¸¡ ---
    # 1. ìŠ¤ì¼€ì¼ë§ (ì¤‘ìš”: fit_transformì´ ì•„ë‹Œ transform)
    data_scaled = _scaler.transform(last_10_days_data)
    
    # 2. í…ì„œ ë³€í™˜ ë° ë°°ì¹˜ ì°¨ì› ì¶”ê°€ [10, 3] -> [1, 10, 3]
    input_tensor = torch.tensor(data_scaled, dtype=torch.float32).unsqueeze(0)
    
    # 3. ì˜ˆì¸¡
    with torch.no_grad(): # ê¸°ìš¸ê¸° ê³„ì‚° ì•ˆí•¨
        prediction_scaled = _model(input_tensor) # (1, 2)
    
    # --- 3-5. ìŠ¤ì¼€ì¼ ì—­ë³€í™˜ ---
    # ì˜ˆì¸¡ëœ [SEC, Hynix] (ìŠ¤ì¼€ì¼ë¨)
    pred_values_scaled = prediction_scaled.cpu().numpy()[0]
    
    # ì—­ë³€í™˜ì„ ìœ„í•´ (3,) í˜•íƒœë¡œ ë§ì¶°ì¤˜ì•¼ í•¨ (Sector_AvgëŠ” 0ìœ¼ë¡œ)
    dummy_features = np.zeros((1, 3))
    dummy_features[0, :2] = pred_values_scaled # ì˜ˆì¸¡ê°’ 2ê°œ ì‚½ì…
    
    # [SEC, Hynix, 0] -> [ì‹¤ì œ SEC, ì‹¤ì œ Hynix, ì‹¤ì œ 0]
    prediction_actual = _scaler.inverse_transform(dummy_features)[0]
    
    pred_sec = prediction_actual[0]
    pred_hynix = prediction_actual[1]
    
    # í”Œë¡œíŒ…ìš© ë°ì´í„° (ìµœê·¼ 150ì¼)
    start_date_plot = (datetime.now() - timedelta(days=150)).strftime('%Y-%m-%d')
    df_plot_dict = {}
    for symbol in target_symbols.keys():
        df_plot_dict[symbol] = fdr.DataReader(symbol, start_date_plot)['Close']
    
    df_plot = pd.DataFrame(df_plot_dict).fillna(method='ffill').rename(columns={
        '005930': 'ì‚¼ì„±ì „ì', '000660': 'SKí•˜ì´ë‹‰ìŠ¤'
    })
    
    df_feature_info = pd.DataFrame({ # ìˆ˜ì •ë¨
        'Symbol': sector_symbols,
        'Name': sector_names
    })
    
    return pred_sec, pred_hynix, df_plot, df_feature_info

# --- 4. Streamlit UI êµ¬ì„± ---
st.set_page_config(page_title="ë°˜ë„ì²´ ì£¼ê°€ ì˜ˆì¸¡ (LSTM)", layout="wide")
st.title("ğŸ“ˆ ë°˜ë„ì²´ ì„¹í„° ê¸°ë°˜ ì£¼ê°€ ì˜ˆì¸¡ (LSTM Pre-trained)")

# 1. ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
with st.spinner('ì‚¬ì „ í•™ìŠµëœ LSTM ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...'):
    model, scaler = load_model_and_scaler()

# 2. ë©”ì¸ ë¡œì§
if model is not None and scaler is not None:
    st.success('ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ!')
    
    # 3. ë°ì´í„° ë¡œë“œ ë° ì˜ˆì¸¡ ìˆ˜í–‰
    with st.spinner('ìµœì‹  ì£¼ê°€ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...'):
        pred_sec, pred_hynix, df_plot, df_feature_info = load_data_and_predict(model, scaler)

    if pred_sec is not None:
        # 4. ì‚¬ì´ë“œë°” - ì˜ˆì¸¡ ê²°ê³¼
        st.sidebar.header("ğŸ”® ë‚´ì¼ ì£¼ê°€ ì˜ˆì¸¡")
        st.sidebar.write(f"({df_plot.index[-1].date()} ê¸°ì¤€ ë°ì´í„°ë¡œ ì˜ˆì¸¡)")

        # ì‚¼ì„±ì „ì
        st.sidebar.subheader("Samsung (005930)")
        last_sec = df_plot['ì‚¼ì„±ì „ì'].iloc[-1]
        delta_sec = (pred_sec - last_sec) / last_sec * 100
        st.sidebar.metric("ì˜ˆì¸¡ ì¢…ê°€", f"{pred_sec:,.0f} ì›", f"{delta_sec:.2f} %")

        # SKí•˜ì´ë‹‰ìŠ¤
        st.sidebar.subheader("SK Hynix (000660)")
        last_hynix = df_plot['SKí•˜ì´ë‹‰ìŠ¤'].iloc[-1]
        delta_hynix = (pred_hynix - last_hynix) / last_hynix * 100
        st.sidebar.metric("ì˜ˆì¸¡ ì¢…ê°€", f"{pred_hynix:,.0f} ì›", f"{delta_hynix:.2f} %")

        # 5. ë©”ì¸ í™”ë©´ - ì°¨íŠ¸
        st.header("ì£¼ìš” ë°ì´í„° ì°¨íŠ¸")
        tab1, tab2 = st.tabs(["ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤"])

        def plot_chart(df, col, title):
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=df.index, y=df[col], name='ì¢…ê°€'))
            fig.add_trace(go.Scatter(x=df.index, y=df[col].rolling(window=20).mean(), name='20ì¼ ì´í‰ì„ '))
            fig.update_layout(title=f"<b>{title}</b>", xaxis_rangeslider_visible=True)
            st.plotly_chart(fig, use_container_width=True)

        with tab1:
            plot_chart(df_plot, 'ì‚¼ì„±ì „ì', 'ì‚¼ì„±ì „ì(005930) ì¢…ê°€')
        with tab2:
            plot_chart(df_plot, 'SKí•˜ì´ë‹‰ìŠ¤', 'SKí•˜ì´ë‹‰ìŠ¤(000660) ì¢…ê°€')
            
        st.info("ì´ ì˜ˆì¸¡ì€ ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤, ê·¸ë¦¬ê³  ì•„ë˜ 5ê°œ ë°˜ë„ì²´ ì¢…ëª©ì˜ í‰ê· ì„ Featureë¡œ ì‚¬ìš©í•œ LSTM ëª¨ë¸ì— ì˜í•´ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.dataframe(df_feature_info.rename(columns={
            'Symbol': 'ì¢…ëª©ì½”ë“œ', 'Name': 'ì¢…ëª©ëª…'
        }))
    else:
        st.error("ë°ì´í„° ìˆ˜ì§‘ ë˜ëŠ” ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
else:
    st.error("ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í•˜ì—¬ ì•±ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
